{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TP6. Decision trees - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## EX.1 -  Using Decision Trees to Diagnose Breast Cancer\n",
    "\n",
    "Now that we have built our first decision trees, it's time to turn our attention to a real dataset: The Breast Cancer Wisconsin dataset <https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)>.\n",
    "\n",
    "In order to make the take feasible, the researchers performed feature extraction on the images, like we did in Chapter 4, Representing Data and Engineering Features. They went through a total of 569 images, and extracted 30 different features that describe the characteristics of the cell nuclei present in the images, including:\n",
    "\n",
    "- cell nucleus texture (represented by the standard deviation of the gray-scale values)\n",
    "\n",
    "- cell nucleus size (calculated as the mean of distances from center to points on the perimeter)\n",
    "\n",
    "- tissue smoothness (local variation in radius lengths)\n",
    "\n",
    "- tissue compactness\n",
    "\n",
    "The goal of the research was then to classify tissue samples into benign and malignant (a binary classification task)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision trees for Classification \n",
    "\n",
    "- the target variable uses a discrete set of values\n",
    "- each node, or leaf, represent class labels while the branches represent conjunctions of features leading to class labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "from IPython.display import Image\n",
    "Image(filename = \"tree_example.jpg\", width = 600, height = 300)\n",
    "\n",
    "#https://www.kaggle.com/code/nisasoylu/decision-tree-implementation-on-cancer-dataset#5.-Decision-Tree-with-Sklearn"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### a) Loading the dataset\n",
    "\n",
    "The full dataset is part of Scikit-Learn's example datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "#from sklearn import datasets  \n",
    "# read the dataset\n",
    "#df=pd.read_csv('Breastcancer.csv', index_col=0)\n",
    "df=pd.read_csv('Breastcancer.csv')\n",
    "df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As in previous examples, all data is contained in a 2-D feature matrix data.data, where the rows represent data samples, and the columns are the feature values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "df.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "source": [
    "#df.dtypes"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#checking missing values\n",
    "df.isnull().sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### b) EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "With a look at the provided feature names, we recognize some that we mentioned above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Since this is a binary classification task, we expect to find exactly two target names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "df.diagnosis.value_counts().plot.bar()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "import plotly.express as px\n",
    "fig = px.pie(df, values='radius_mean', names='diagnosis', title='Relation')\n",
    "fig.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "sns.lmplot(y='radius_mean', x='smoothness_mean', hue='diagnosis', \n",
    "           data=df, \n",
    "           fit_reg=False, scatter_kws={'alpha':1})"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Retirar a coluna do id e da Unnamed: 32, cujos gráficos não fazem sentido\n",
    "\n",
    "df=df.drop([\"id\",\"Unnamed: 32\"],axis=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "fig, ax = plt.subplots(10, 3, figsize=(20, 40))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, col in enumerate(df.columns[1:]):\n",
    "    #sns.boxplot(x='diagnosis', y=col, data=df, ax=ax[i], palette='Greens', hue='diagnosis', legend=False)\n",
    "    sns.boxplot(x='diagnosis', y=col, data=df, ax=ax[i], palette='Greens', hue='diagnosis')\n",
    "    ax[i].set_xlabel('Diagnosis', fontsize = 15, fontweight = 'bold')\n",
    "    ax[i].set_ylabel(col, fontsize = 15, fontweight = 'bold')\n",
    "    \n",
    "plt.tight_layout(w_pad=5, h_pad=5)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "fig, ax = plt.subplots(10, 3, figsize=(20, 40))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, col in enumerate(df.columns[1:]):\n",
    "    sns.kdeplot(x=col, data=df, ax=ax[i], fill=True, lw=2, hue = 'diagnosis')\n",
    "    ax[i].set_xlabel(col, fontsize = 15, fontweight = 'bold')\n",
    "    ax[i].set_ylabel('')\n",
    "    \n",
    "plt.tight_layout(w_pad=5, h_pad=5)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### c) Holdout: split the dataset into training and test sets using a 70-30 split:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#target variable\n",
    "y = df.loc[:,\"diagnosis\"].values\n",
    "#feature variable\n",
    "X = df.drop([\"diagnosis\"],axis=1).values"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# our target variable has two categories, M and B. Scikit-learn likes to work with numpy arrays. \n",
    "#Let’s encode the target variable with label encoder. \n",
    "#Hint: This transformer should be used to encode target values, i.e. y, and not the input X.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "#fit and transform the target variable\n",
    "y = le.fit_transform(y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "from IPython.display import Image\n",
    "Image(filename = \"Label_encod.png\", width = 500, height = 300)\n",
    "\n",
    "#Pandas: import pandas as pd; pd.get_dummies()\n",
    "#Sklearn: from sklearn.preprocessing import OneHotEncoder; OneHotEncoder()    \n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#train and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=123)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "X_train.shape, X_test.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Building the decision tree model\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state = 42)\n",
    "\n",
    "#build the model with training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# com scale\n",
    "# model = dt.fit(scaler.transform(X_train), y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# tree visualization\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import plot_tree, export_text\n",
    "from IPython.display import Image, display\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# plot tree\n",
    "plt.figure(figsize=(12,15))  # set plot size (denoted in inches)\n",
    "plot_tree(clf, \n",
    "          feature_names = list(df.columns),\n",
    "          class_names = list(df['diagnosis']),\n",
    "          filled=True,                    \n",
    "          fontsize=6);"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we did not specify any pre-pruning parameters, we would expect this decision tree to grow quite large and result in a perfect score on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "clf.score(X_train, y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, to our surprise, the test error is not too shabby, either:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "clf.score(X_test, y_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let’s predict the training and the test values with this model.\n",
    "\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Let’s take a look at the performance of the model on the training and test set. \n",
    "#To do this, we can use the accuracy_score function. \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tree_train = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Train Accuracy:\", tree_train)\n",
    "\n",
    "tree_test = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", tree_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lets also get the training error rate of the tree model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cmatrix = confusion_matrix(y_true = y_train, y_pred=clf.predict(X_train), labels=[True, False])\n",
    "print(cmatrix)\n",
    "\n",
    "error_rate = (cmatrix[0,1]+cmatrix[1,0])/cmatrix.sum()\n",
    "print(\"Training Error Rate:\", error_rate)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lets compute the error rate of the tree model\n",
    "\n",
    "ypred = clf.predict(X_test)\n",
    "cmatrix = confusion_matrix(y_true=y_test, y_pred=ypred, labels=[True, False])\n",
    "print(cmatrix)\n",
    "error_rate_test = (cmatrix[0,1]+cmatrix[1,0])/cmatrix.sum()\n",
    "print(\"Test Error Rate:\", error_rate_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### d) Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cmatrix, display_labels=[True, False])\n",
    "disp.plot()\n",
    "\n",
    "accuracy_score(y_test,ypred)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### f) Confusion matrix implementation - matriz_confusao(actual, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular a matriz de confusão para um problema de classificação 2-classes:\n",
    "\n",
    "- True positives (TP): O número de casos corretamente classificados para a classe positiva.\n",
    "- True negatives (TN): O número de casos corretamente classificados para a classe negativa.\n",
    "- False positives (FP): O número de casos incorretamente classificados para a classe positiva.\n",
    "- False negatives (FN): O número de casos incorretamente classificados para a classe negativa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Metrics - 2 classes\n",
    "\n",
    "Image(filename = \"matriz_conf_metricas.png\", width = 600, height = 300)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics for Performance Evaluation (Medidas de desempenho)\n",
    "\n",
    "- Accuracy: Rate of correct examples (out of total examples)\n",
    "\n",
    "- Error rate: Rate of wrong examples (out of total examples)\n",
    "\n",
    "- Precision: rate of positive examples classified correctly, among all predicted as positive\n",
    "\n",
    "- Recall (sensitivity): success rate in the positive class (of the total positives, how many were detected)\n",
    "\n",
    "- F1:. Harmonic average of precision and recall with the aim of giving a unique measure that equally values the mistakes made in either direction (FP or FN)\n",
    "\n",
    "  - F1 =  2 x Precision x Recall/(Precision + Recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# confusion matrix in sklearn\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def matriz_confusao(actual, predicted):\n",
    "\n",
    "    # outcome values order in sklearn\n",
    "    matrix = confusion_matrix(y_true = actual, y_pred = predicted, labels=[True, False])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=[True, False])\n",
    "    disp.plot()\n",
    "\n",
    "    # classification report for precision, recall f1-score and accuracy\n",
    "    matrix = classification_report(actual,predicted)\n",
    "    print('Classification report : \\n',matrix)\n",
    "\n",
    "# chamada à função\n",
    "res = matriz_confusao(y_test,ypred)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### e) Holdout - 10x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Holdout\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize your machine learning model \n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "scores = []\n",
    "\n",
    "# Iterate through each fold\n",
    "for i in range(10):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy score for this fold\n",
    "    fold_score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Append the fold score to the list of scores\n",
    "    scores.append(fold_score)\n",
    "    \n",
    "# Calculate the mean accuracy across all folds\n",
    "mean_accuracy = np.mean(scores)\n",
    "print(\"Holdout Scores:\", scores)\n",
    "print(\"Mean Accuracy:\", mean_accuracy)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### g) K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# K-Fold Cross Validation - implementation\n",
    "#\n",
    "# Splitting the Data into Folds\n",
    "\n",
    "def kfold_indices(data, k):\n",
    "    fold_size = len(data) // k\n",
    "    indices = np.arange(len(data))\n",
    "    folds = []\n",
    "    for i in range(k):\n",
    "        test_indices = indices[i * fold_size : (i + 1) * fold_size]\n",
    "        train_indices = np.concatenate([indices[:i * fold_size], indices[(i + 1) * fold_size:]])\n",
    "        folds.append((train_indices, test_indices))\n",
    "    return folds\n",
    "\n",
    "# Define the number of folds (K)\n",
    "k = 5\n",
    "\n",
    "# Get the fold indices\n",
    "fold_indices = kfold_indices(X, k)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Performing K-Fold Cross-Validation\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize your machine learning model \n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "scores = []\n",
    "prevs_folds=[]\n",
    "y_folds=[]\n",
    "# Iterate through each fold\n",
    "for train_indices, test_indices in fold_indices:\n",
    "    X_train, y_train = X[train_indices], y[train_indices]\n",
    "    X_test, y_test = X[test_indices], y[test_indices]\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy score for this fold\n",
    "    fold_score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Append the fold score to the list of scores\n",
    "    scores.append(fold_score)\n",
    "\n",
    "\n",
    "    # Append the prevs and labels of the test set\n",
    "    prevs_folds.append(y_pred)\n",
    "    y_folds.append(y_test)\n",
    "\n",
    "\n",
    "# Calculate the mean accuracy across all folds\n",
    "mean_accuracy = np.mean(scores)\n",
    "std_accuracy=np.std(scores)\n",
    "print(\"K-Fold Cross-Validation Scores:\", scores)\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Standart Deviation:\", std_accuracy)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "resultados = matriz_confusao(np.concatenate(y_folds), np.concatenate(prevs_folds))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning / Overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "source": [
    "# The score on the training set is 100%, but the score on the test set is 95%. This means that our model has an overfitting problem. \n",
    "# Note that the decision tree model learned the training set very well, but the model cannot generalize. \n",
    "# To overcome the overfitting problem, we control the complexity of a tree. We can start to specify the max_depth parameter \n",
    "# which controls the maximum number of levels. The default value for the max_depth parameter is None, which means that the tree can grow as large as possible. \n",
    "# We can try a smaller value and compare the results. Let me specify the max_depth parameter."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "source": [
    "# Now we want to do some model exploration. For example, we mentioned above that the depth of a tree influences its performance. \n",
    "# If we wanted to study this dependency more systematically, we could repeat building the tree for different values of max_depth:\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=123)\n",
    "\n",
    "import numpy as np\n",
    "max_depths = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "source": [
    "# For each of these values, we want to run the full model cascade from start to finish. \n",
    "# We also want to record the train and test scores. We do this in a for loop:\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "for d in max_depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=d, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score.append(clf.score(X_train, y_train))\n",
    "    test_score.append(clf.score(X_test, y_test))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "source": [
    "# We can plot the scores as a function of the tree depth using Matplotlib:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depths, train_score, 'o-', linewidth=3, label='train')\n",
    "plt.plot(max_depths, test_score, 's-', linewidth=3, label='test')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('score')\n",
    "plt.ylim(0.8, 1.1)\n",
    "plt.legend();"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "source": [
    "# What about the minimum numbers of samples required to make a node a leaf node? (another Hyperparameter)\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "min_samples = np.array([2, 4, 8, 16, 32])\n",
    "for s in min_samples:\n",
    "    clf = DecisionTreeClassifier(min_samples_leaf=s, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score.append(clf.score(X_train, y_train))\n",
    "    test_score.append(clf.score(X_test, y_test))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(min_samples, train_score, 'o-', linewidth=3, label='train')\n",
    "plt.plot(min_samples, test_score, 's-', linewidth=3, label='test')\n",
    "plt.xlabel('min_samples_leaf')\n",
    "plt.ylabel('score')\n",
    "plt.ylim(0.8, 1)\n",
    "plt.legend()"
   ],
   "outputs": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Hint: To find the best parameters, we can use GridSearchCV \n",
    "#(https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "\n",
    "# Refs:\n",
    "# https://tirendazacademy.medium.com/breast-cancer-detection-with-decision-trees-f66637ac482e\n",
    "# https://www.kaggle.com/code/nisasoylu/decision-tree-implementation-on-cancer-dataset?scriptVersionId=38312678&cellId=28\n",
    "# https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
